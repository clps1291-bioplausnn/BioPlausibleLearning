{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sys.path.append('../')\n",
    "from data.load_data import *\n",
    "from models.neural_networks import *\n",
    "from train.train_cnn import *\n",
    "from train.train_fcn import *\n",
    "from train.train_semihebb import *\n",
    "from evaluation.test import *\n",
    "from utils.others import *\n",
    "from utils.plot import *\n",
    "from utils.save_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Hebb rule\n",
    "\n",
    "note that hebbian weights goes to infinity, values will be NaN after they go out of the range, so tSNE plot cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 2.320737838745117, Accuracy: 11.35%\n",
      "Epoch: 0, Step: 50, Loss: 1.9118914604187012, Accuracy: 31.28%\n",
      "Epoch: 0, Step: 100, Loss: 1.8061134815216064, Accuracy: 36.31%\n",
      "Epoch: 0, Step: 150, Loss: 1.562354564666748, Accuracy: 49.0%\n",
      "Epoch: 0, Step: 200, Loss: 1.3082427978515625, Accuracy: 59.44%\n",
      "Epoch: 0, Step: 250, Loss: 1.6132625341415405, Accuracy: 67.73%\n",
      "Epoch: 0, Step: 300, Loss: 1.298007845878601, Accuracy: 69.16%\n",
      "Epoch: 0, Step: 350, Loss: 1.1100846529006958, Accuracy: 66.96%\n",
      "Epoch: 0, Step: 400, Loss: 1.1102190017700195, Accuracy: 75.45%\n",
      "Epoch: 0, Step: 450, Loss: 1.1770377159118652, Accuracy: 65.27%\n",
      "Epoch: 0, Step: 500, Loss: 0.8903278112411499, Accuracy: 75.43%\n",
      "Epoch: 0, Step: 550, Loss: 0.7944438457489014, Accuracy: 65.44%\n",
      "Epoch: 0, Step: 600, Loss: 0.9019562005996704, Accuracy: 83.08%\n",
      "Epoch: 0, Step: 650, Loss: 0.6638520956039429, Accuracy: 81.49%\n",
      "Epoch: 0, Step: 700, Loss: 0.7416394948959351, Accuracy: 71.66%\n",
      "Epoch: 0, Step: 750, Loss: 0.8208505511283875, Accuracy: 80.58%\n",
      "Epoch: 0, Step: 800, Loss: 0.988426685333252, Accuracy: 74.81%\n",
      "Epoch: 0, Step: 850, Loss: 0.7310705780982971, Accuracy: 74.24%\n",
      "Epoch: 0, Step: 900, Loss: 0.653241753578186, Accuracy: 75.78%\n",
      "Epoch: 0, Step: 950, Loss: 0.6130303740501404, Accuracy: 78.55%\n",
      "Epoch: 0, Step: 1000, Loss: 0.6668863892555237, Accuracy: 82.07%\n",
      "Epoch: 0, Step: 1050, Loss: 0.6770164966583252, Accuracy: 86.84%\n",
      "Epoch: 0, Step: 1100, Loss: 0.31176114082336426, Accuracy: 85.11%\n",
      "Epoch: 0, Step: 1150, Loss: 0.4025838077068329, Accuracy: 82.23%\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001             \n",
    "TSNE = True\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "#load CIFAR-10 dataset\n",
    "\n",
    "# Plot one example\n",
    "plot_example(train_loader)\n",
    "\n",
    "TSNE = False\n",
    "\n",
    "# create model instance\n",
    "\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='hebb',p=None)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SemiHebbNet on the MNIST test images: 78.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Oja's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "Epoch: 0, Step: 0, Loss: 2.314085006713867, Accuracy: 9.43%\n",
      "Epoch: 0, Step: 50, Loss: 2.2312917709350586, Accuracy: 29.21%\n",
      "Epoch: 0, Step: 100, Loss: 2.1097075939178467, Accuracy: 54.85%\n",
      "Epoch: 0, Step: 150, Loss: 1.9586182832717896, Accuracy: 61.1%\n",
      "Epoch: 0, Step: 200, Loss: 1.864109992980957, Accuracy: 63.63%\n",
      "Epoch: 0, Step: 250, Loss: 1.6955351829528809, Accuracy: 70.86%\n",
      "Epoch: 0, Step: 300, Loss: 1.6053637266159058, Accuracy: 68.47%\n",
      "Epoch: 0, Step: 350, Loss: 1.5876286029815674, Accuracy: 70.69%\n",
      "Epoch: 0, Step: 400, Loss: 1.4423426389694214, Accuracy: 77.01%\n",
      "Epoch: 0, Step: 450, Loss: 1.4346058368682861, Accuracy: 76.99%\n",
      "Epoch: 0, Step: 500, Loss: 1.3831783533096313, Accuracy: 79.45%\n",
      "Epoch: 0, Step: 550, Loss: 1.293118953704834, Accuracy: 80.01%\n",
      "Epoch: 0, Step: 600, Loss: 1.2180126905441284, Accuracy: 81.03%\n",
      "Epoch: 0, Step: 650, Loss: 1.204261302947998, Accuracy: 81.51%\n",
      "Epoch: 0, Step: 700, Loss: 1.1364930868148804, Accuracy: 82.05%\n",
      "Epoch: 0, Step: 750, Loss: 1.0642225742340088, Accuracy: 81.18%\n",
      "Epoch: 0, Step: 800, Loss: 1.2223716974258423, Accuracy: 83.3%\n",
      "Epoch: 0, Step: 850, Loss: 1.109928011894226, Accuracy: 82.82%\n",
      "Epoch: 0, Step: 900, Loss: 1.058547854423523, Accuracy: 83.69%\n",
      "Epoch: 0, Step: 950, Loss: 0.9861540794372559, Accuracy: 84.22%\n",
      "Epoch: 0, Step: 1000, Loss: 0.8617392778396606, Accuracy: 82.4%\n",
      "Epoch: 0, Step: 1050, Loss: 0.8583933115005493, Accuracy: 84.61%\n",
      "Epoch: 0, Step: 1100, Loss: 0.8422145247459412, Accuracy: 84.04%\n",
      "Epoch: 0, Step: 1150, Loss: 0.9008110165596008, Accuracy: 84.83%\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.0001             \n",
    "TSNE = False\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "\n",
    "# create model instance\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='oja',p=None)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                  \n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SemiHebbNet on the MNIST test images: 84.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Gupta's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "Epoch: 0, Step: 0, Loss: 2.271906852722168, Accuracy: 9.87%\n",
      "Epoch: 0, Step: 50, Loss: 1.1152454614639282, Accuracy: 82.22%\n",
      "Epoch: 0, Step: 100, Loss: 0.9718872308731079, Accuracy: 84.41%\n",
      "Epoch: 0, Step: 150, Loss: 0.720020055770874, Accuracy: 86.05%\n",
      "Epoch: 0, Step: 200, Loss: 0.5295201539993286, Accuracy: 87.28%\n",
      "Epoch: 0, Step: 250, Loss: 0.44981735944747925, Accuracy: 87.9%\n",
      "Epoch: 0, Step: 300, Loss: 0.539824366569519, Accuracy: 88.53%\n",
      "Epoch: 0, Step: 350, Loss: 0.4347555935382843, Accuracy: 88.91%\n",
      "Epoch: 0, Step: 400, Loss: 0.5639405250549316, Accuracy: 89.2%\n",
      "Epoch: 0, Step: 450, Loss: 0.45153340697288513, Accuracy: 89.71%\n",
      "Epoch: 0, Step: 500, Loss: 0.3094148635864258, Accuracy: 90.11%\n",
      "Epoch: 0, Step: 550, Loss: 0.6013135313987732, Accuracy: 90.02%\n",
      "Epoch: 0, Step: 600, Loss: 0.29083943367004395, Accuracy: 90.4%\n",
      "Epoch: 0, Step: 650, Loss: 0.269441694021225, Accuracy: 90.97%\n",
      "Epoch: 0, Step: 700, Loss: 0.49379950761795044, Accuracy: 90.79%\n",
      "Epoch: 0, Step: 750, Loss: 0.3686995208263397, Accuracy: 90.62%\n",
      "Epoch: 0, Step: 800, Loss: 0.5195204019546509, Accuracy: 91.13%\n",
      "Epoch: 0, Step: 850, Loss: 0.3255181610584259, Accuracy: 91.27%\n",
      "Epoch: 0, Step: 900, Loss: 0.313215434551239, Accuracy: 91.06%\n",
      "Epoch: 0, Step: 950, Loss: 0.38048407435417175, Accuracy: 91.39%\n",
      "Epoch: 0, Step: 1000, Loss: 0.29418033361434937, Accuracy: 91.25%\n",
      "Epoch: 0, Step: 1050, Loss: 0.32999083399772644, Accuracy: 91.59%\n",
      "Epoch: 0, Step: 1100, Loss: 0.23694011569023132, Accuracy: 91.52%\n",
      "Epoch: 0, Step: 1150, Loss: 0.2171785533428192, Accuracy: 91.77%\n",
      "Epoch: 1, Step: 0, Loss: 0.44780004024505615, Accuracy: 85.31%\n",
      "Epoch: 1, Step: 50, Loss: 0.7239016890525818, Accuracy: 90.61%\n",
      "Epoch: 1, Step: 100, Loss: 0.4623452126979828, Accuracy: 90.89%\n",
      "Epoch: 1, Step: 150, Loss: 0.48550358414649963, Accuracy: 90.78%\n",
      "Epoch: 1, Step: 200, Loss: 0.47676756978034973, Accuracy: 90.8%\n",
      "Epoch: 1, Step: 250, Loss: 0.5082646012306213, Accuracy: 90.9%\n",
      "Epoch: 1, Step: 300, Loss: 0.44648346304893494, Accuracy: 90.98%\n",
      "Epoch: 1, Step: 350, Loss: 0.2956494688987732, Accuracy: 90.83%\n",
      "Epoch: 1, Step: 400, Loss: 0.4245257079601288, Accuracy: 91.11%\n",
      "Epoch: 1, Step: 450, Loss: 0.3895542025566101, Accuracy: 91.1%\n",
      "Epoch: 1, Step: 500, Loss: 0.5867778062820435, Accuracy: 91.28%\n",
      "Epoch: 1, Step: 550, Loss: 0.34985101222991943, Accuracy: 91.48%\n",
      "Epoch: 1, Step: 600, Loss: 0.4796709418296814, Accuracy: 91.35%\n",
      "Epoch: 1, Step: 650, Loss: 0.3153322637081146, Accuracy: 91.35%\n",
      "Epoch: 1, Step: 700, Loss: 0.4282110333442688, Accuracy: 91.39%\n",
      "Epoch: 1, Step: 750, Loss: 0.28994694352149963, Accuracy: 91.49%\n",
      "Epoch: 1, Step: 800, Loss: 0.33408135175704956, Accuracy: 91.6%\n",
      "Epoch: 1, Step: 850, Loss: 0.3224855363368988, Accuracy: 91.72%\n",
      "Epoch: 1, Step: 900, Loss: 0.2545603811740875, Accuracy: 91.96%\n",
      "Epoch: 1, Step: 950, Loss: 0.4684208631515503, Accuracy: 91.68%\n",
      "Epoch: 1, Step: 1000, Loss: 0.27955731749534607, Accuracy: 91.78%\n",
      "Epoch: 1, Step: 1050, Loss: 0.22256240248680115, Accuracy: 91.8%\n",
      "Epoch: 1, Step: 1100, Loss: 0.708649218082428, Accuracy: 91.86%\n",
      "Epoch: 1, Step: 1150, Loss: 0.22335343062877655, Accuracy: 91.93%\n",
      "Epoch: 2, Step: 0, Loss: 0.41051962971687317, Accuracy: 91.29%\n",
      "Epoch: 2, Step: 50, Loss: 0.44029566645622253, Accuracy: 92.1%\n",
      "Epoch: 2, Step: 100, Loss: 0.4251004755496979, Accuracy: 92.11%\n",
      "Epoch: 2, Step: 150, Loss: 0.36261847615242004, Accuracy: 91.97%\n",
      "Epoch: 2, Step: 200, Loss: 0.3706217110157013, Accuracy: 92.14%\n",
      "Epoch: 2, Step: 250, Loss: 0.3455949127674103, Accuracy: 92.05%\n",
      "Epoch: 2, Step: 300, Loss: 0.34087005257606506, Accuracy: 91.98%\n",
      "Epoch: 2, Step: 350, Loss: 0.34702932834625244, Accuracy: 92.29%\n",
      "Epoch: 2, Step: 400, Loss: 0.3461824357509613, Accuracy: 92.2%\n",
      "Epoch: 2, Step: 450, Loss: 0.36850130558013916, Accuracy: 92.15%\n",
      "Epoch: 2, Step: 500, Loss: 0.18183742463588715, Accuracy: 92.21%\n",
      "Epoch: 2, Step: 550, Loss: 0.4286446273326874, Accuracy: 92.01%\n",
      "Epoch: 2, Step: 600, Loss: 0.2153649479150772, Accuracy: 92.16%\n",
      "Epoch: 2, Step: 650, Loss: 0.2591560482978821, Accuracy: 92.13%\n",
      "Epoch: 2, Step: 700, Loss: 0.4378257691860199, Accuracy: 92.21%\n",
      "Epoch: 2, Step: 750, Loss: 0.17056122422218323, Accuracy: 92.36%\n",
      "Epoch: 2, Step: 800, Loss: 0.27749311923980713, Accuracy: 92.34%\n",
      "Epoch: 2, Step: 850, Loss: 0.25755634903907776, Accuracy: 92.34%\n",
      "Epoch: 2, Step: 900, Loss: 0.2289818376302719, Accuracy: 92.38%\n",
      "Epoch: 2, Step: 950, Loss: 0.30569878220558167, Accuracy: 92.47%\n",
      "Epoch: 2, Step: 1000, Loss: 0.36395251750946045, Accuracy: 92.54%\n",
      "Epoch: 2, Step: 1050, Loss: 0.3038979470729828, Accuracy: 92.69%\n",
      "Epoch: 2, Step: 1100, Loss: 0.3532094955444336, Accuracy: 92.64%\n",
      "Epoch: 2, Step: 1150, Loss: 0.4580675959587097, Accuracy: 92.66%\n",
      "Epoch: 3, Step: 0, Loss: 0.27614909410476685, Accuracy: 92.49%\n",
      "Epoch: 3, Step: 50, Loss: 0.30075642466545105, Accuracy: 92.51%\n",
      "Epoch: 3, Step: 100, Loss: 0.41939979791641235, Accuracy: 92.43%\n",
      "Epoch: 3, Step: 150, Loss: 0.33309006690979004, Accuracy: 92.39%\n",
      "Epoch: 3, Step: 200, Loss: 0.26590806245803833, Accuracy: 92.42%\n",
      "Epoch: 3, Step: 250, Loss: 0.27892211079597473, Accuracy: 92.42%\n",
      "Epoch: 3, Step: 300, Loss: 0.4637949764728546, Accuracy: 92.48%\n",
      "Epoch: 3, Step: 350, Loss: 0.295357346534729, Accuracy: 92.44%\n",
      "Epoch: 3, Step: 400, Loss: 0.5177326798439026, Accuracy: 92.54%\n",
      "Epoch: 3, Step: 450, Loss: 0.43542540073394775, Accuracy: 92.55%\n",
      "Epoch: 3, Step: 500, Loss: 0.42149391770362854, Accuracy: 92.53%\n",
      "Epoch: 3, Step: 550, Loss: 0.25169384479522705, Accuracy: 92.54%\n",
      "Epoch: 3, Step: 600, Loss: 0.2613975703716278, Accuracy: 92.59%\n",
      "Epoch: 3, Step: 650, Loss: 0.21128979325294495, Accuracy: 92.62%\n",
      "Epoch: 3, Step: 700, Loss: 0.4594503343105316, Accuracy: 92.56%\n",
      "Epoch: 3, Step: 750, Loss: 0.250609427690506, Accuracy: 92.62%\n",
      "Epoch: 3, Step: 800, Loss: 0.29656708240509033, Accuracy: 92.61%\n",
      "Epoch: 3, Step: 850, Loss: 0.2122846394777298, Accuracy: 92.66%\n",
      "Epoch: 3, Step: 900, Loss: 0.2484823763370514, Accuracy: 92.69%\n",
      "Epoch: 3, Step: 950, Loss: 0.1853124052286148, Accuracy: 92.65%\n",
      "Epoch: 3, Step: 1000, Loss: 0.16282299160957336, Accuracy: 92.7%\n",
      "Epoch: 3, Step: 1050, Loss: 0.38794800639152527, Accuracy: 92.63%\n",
      "Epoch: 3, Step: 1100, Loss: 0.41787150502204895, Accuracy: 92.69%\n",
      "Epoch: 3, Step: 1150, Loss: 0.19427260756492615, Accuracy: 92.62%\n",
      "Epoch: 4, Step: 0, Loss: 0.2421155422925949, Accuracy: 91.7%\n",
      "Epoch: 4, Step: 50, Loss: 0.5144981741905212, Accuracy: 92.1%\n",
      "Epoch: 4, Step: 100, Loss: 0.3715655505657196, Accuracy: 92.2%\n",
      "Epoch: 4, Step: 150, Loss: 0.30242881178855896, Accuracy: 92.27%\n",
      "Epoch: 4, Step: 200, Loss: 0.45298412442207336, Accuracy: 92.21%\n",
      "Epoch: 4, Step: 250, Loss: 0.45061904191970825, Accuracy: 92.22%\n",
      "Epoch: 4, Step: 300, Loss: 0.2620263695716858, Accuracy: 92.21%\n",
      "Epoch: 4, Step: 350, Loss: 0.2603958249092102, Accuracy: 92.26%\n",
      "Epoch: 4, Step: 400, Loss: 0.38145628571510315, Accuracy: 92.31%\n",
      "Epoch: 4, Step: 450, Loss: 0.3318592309951782, Accuracy: 92.23%\n",
      "Epoch: 4, Step: 500, Loss: 0.41041091084480286, Accuracy: 92.27%\n",
      "Epoch: 4, Step: 550, Loss: 0.3453645706176758, Accuracy: 92.24%\n",
      "Epoch: 4, Step: 600, Loss: 0.3334636986255646, Accuracy: 92.19%\n",
      "Epoch: 4, Step: 650, Loss: 0.31744319200515747, Accuracy: 92.31%\n",
      "Epoch: 4, Step: 700, Loss: 0.428243488073349, Accuracy: 92.31%\n",
      "Epoch: 4, Step: 750, Loss: 0.2480926364660263, Accuracy: 92.33%\n",
      "Epoch: 4, Step: 800, Loss: 0.27951115369796753, Accuracy: 92.34%\n",
      "Epoch: 4, Step: 850, Loss: 0.31440120935440063, Accuracy: 92.4%\n",
      "Epoch: 4, Step: 900, Loss: 0.3361623287200928, Accuracy: 92.36%\n",
      "Epoch: 4, Step: 950, Loss: 0.4207215905189514, Accuracy: 92.43%\n",
      "Epoch: 4, Step: 1000, Loss: 0.3040633499622345, Accuracy: 92.43%\n",
      "Epoch: 4, Step: 1050, Loss: 0.369105726480484, Accuracy: 92.39%\n",
      "Epoch: 4, Step: 1100, Loss: 0.3484076261520386, Accuracy: 92.38%\n",
      "Epoch: 4, Step: 1150, Loss: 0.16824956238269806, Accuracy: 92.38%\n",
      "Epoch: 5, Step: 0, Loss: 0.20953772962093353, Accuracy: 90.8%\n",
      "Epoch: 5, Step: 50, Loss: 0.4997674226760864, Accuracy: 91.42%\n",
      "Epoch: 5, Step: 100, Loss: 0.455531507730484, Accuracy: 91.36%\n",
      "Epoch: 5, Step: 150, Loss: 0.5148926377296448, Accuracy: 91.34%\n",
      "Epoch: 5, Step: 200, Loss: 0.38132181763648987, Accuracy: 91.44%\n",
      "Epoch: 5, Step: 250, Loss: 0.44716212153434753, Accuracy: 91.48%\n",
      "Epoch: 5, Step: 300, Loss: 0.3765185475349426, Accuracy: 91.41%\n",
      "Epoch: 5, Step: 350, Loss: 0.4081305265426636, Accuracy: 91.52%\n",
      "Epoch: 5, Step: 400, Loss: 0.46162617206573486, Accuracy: 91.48%\n",
      "Epoch: 5, Step: 450, Loss: 0.3928092122077942, Accuracy: 91.5%\n",
      "Epoch: 5, Step: 500, Loss: 0.3623742163181305, Accuracy: 91.55%\n",
      "Epoch: 5, Step: 550, Loss: 0.25294408202171326, Accuracy: 91.5%\n",
      "Epoch: 5, Step: 600, Loss: 0.3666952848434448, Accuracy: 91.45%\n",
      "Epoch: 5, Step: 650, Loss: 0.39203497767448425, Accuracy: 91.46%\n",
      "Epoch: 5, Step: 700, Loss: 0.4266025125980377, Accuracy: 91.49%\n",
      "Epoch: 5, Step: 750, Loss: 0.5038062930107117, Accuracy: 91.47%\n",
      "Epoch: 5, Step: 800, Loss: 0.5351879596710205, Accuracy: 91.45%\n",
      "Epoch: 5, Step: 850, Loss: 0.3904300928115845, Accuracy: 91.46%\n",
      "Epoch: 5, Step: 900, Loss: 0.5269424319267273, Accuracy: 91.49%\n",
      "Epoch: 5, Step: 950, Loss: 0.3076545298099518, Accuracy: 91.49%\n",
      "Epoch: 5, Step: 1000, Loss: 0.22387933731079102, Accuracy: 91.53%\n",
      "Epoch: 5, Step: 1050, Loss: 0.4086759090423584, Accuracy: 91.56%\n",
      "Epoch: 5, Step: 1100, Loss: 0.3947461247444153, Accuracy: 91.54%\n",
      "Epoch: 5, Step: 1150, Loss: 0.27038225531578064, Accuracy: 91.53%\n",
      "Epoch: 6, Step: 0, Loss: 0.2601938247680664, Accuracy: 89.91%\n",
      "Epoch: 6, Step: 50, Loss: 0.4709623456001282, Accuracy: 90.55%\n",
      "Epoch: 6, Step: 100, Loss: 0.3508602976799011, Accuracy: 90.64%\n",
      "Epoch: 6, Step: 150, Loss: 0.4791552722454071, Accuracy: 90.81%\n",
      "Epoch: 6, Step: 200, Loss: 0.4295564591884613, Accuracy: 90.76%\n",
      "Epoch: 6, Step: 250, Loss: 0.3881341814994812, Accuracy: 90.78%\n",
      "Epoch: 6, Step: 300, Loss: 0.5961891412734985, Accuracy: 90.85%\n",
      "Epoch: 6, Step: 350, Loss: 0.5206243991851807, Accuracy: 90.74%\n",
      "Epoch: 6, Step: 400, Loss: 0.4300438165664673, Accuracy: 90.76%\n",
      "Epoch: 6, Step: 450, Loss: 0.3819507658481598, Accuracy: 90.8%\n",
      "Epoch: 6, Step: 500, Loss: 0.47241848707199097, Accuracy: 90.76%\n",
      "Epoch: 6, Step: 550, Loss: 0.4216594994068146, Accuracy: 90.8%\n",
      "Epoch: 6, Step: 600, Loss: 0.384596586227417, Accuracy: 90.81%\n",
      "Epoch: 6, Step: 650, Loss: 0.3566593527793884, Accuracy: 90.83%\n",
      "Epoch: 6, Step: 700, Loss: 0.5837696194648743, Accuracy: 90.86%\n",
      "Epoch: 6, Step: 750, Loss: 0.5249536633491516, Accuracy: 90.89%\n",
      "Epoch: 6, Step: 800, Loss: 0.46139729022979736, Accuracy: 90.91%\n",
      "Epoch: 6, Step: 850, Loss: 0.6202905774116516, Accuracy: 90.89%\n",
      "Epoch: 6, Step: 900, Loss: 0.37524574995040894, Accuracy: 90.86%\n",
      "Epoch: 6, Step: 950, Loss: 0.2941782474517822, Accuracy: 90.84%\n",
      "Epoch: 6, Step: 1000, Loss: 0.5243459343910217, Accuracy: 90.82%\n",
      "Epoch: 6, Step: 1050, Loss: 0.3101232051849365, Accuracy: 90.88%\n",
      "Epoch: 6, Step: 1100, Loss: 0.25014859437942505, Accuracy: 90.86%\n",
      "Epoch: 6, Step: 1150, Loss: 0.3411143124103546, Accuracy: 90.89%\n",
      "Epoch: 7, Step: 0, Loss: 0.2510524392127991, Accuracy: 88.72%\n",
      "Epoch: 7, Step: 50, Loss: 0.6773817539215088, Accuracy: 89.18%\n",
      "Epoch: 7, Step: 100, Loss: 0.48401549458503723, Accuracy: 89.46%\n",
      "Epoch: 7, Step: 150, Loss: 0.6271327137947083, Accuracy: 89.62%\n",
      "Epoch: 7, Step: 200, Loss: 0.3750927448272705, Accuracy: 89.64%\n",
      "Epoch: 7, Step: 250, Loss: 0.5161045789718628, Accuracy: 89.62%\n",
      "Epoch: 7, Step: 300, Loss: 0.4709874987602234, Accuracy: 89.54%\n",
      "Epoch: 7, Step: 350, Loss: 0.4447205364704132, Accuracy: 89.62%\n",
      "Epoch: 7, Step: 400, Loss: 0.6256874203681946, Accuracy: 89.62%\n",
      "Epoch: 7, Step: 450, Loss: 0.4660942852497101, Accuracy: 89.65%\n",
      "Epoch: 7, Step: 500, Loss: 0.33844029903411865, Accuracy: 89.62%\n",
      "Epoch: 7, Step: 550, Loss: 0.3715418577194214, Accuracy: 89.67%\n",
      "Epoch: 7, Step: 600, Loss: 0.6163970828056335, Accuracy: 89.67%\n",
      "Epoch: 7, Step: 650, Loss: 0.4056014120578766, Accuracy: 89.67%\n",
      "Epoch: 7, Step: 700, Loss: 0.584273636341095, Accuracy: 89.72%\n",
      "Epoch: 7, Step: 750, Loss: 0.5299082398414612, Accuracy: 89.7%\n",
      "Epoch: 7, Step: 800, Loss: 0.5379848480224609, Accuracy: 89.69%\n",
      "Epoch: 7, Step: 850, Loss: 0.43557724356651306, Accuracy: 89.75%\n",
      "Epoch: 7, Step: 900, Loss: 0.40522661805152893, Accuracy: 89.83%\n",
      "Epoch: 7, Step: 950, Loss: 0.5694110989570618, Accuracy: 89.73%\n",
      "Epoch: 7, Step: 1000, Loss: 0.5498948693275452, Accuracy: 89.74%\n",
      "Epoch: 7, Step: 1050, Loss: 0.3762349784374237, Accuracy: 89.72%\n",
      "Epoch: 7, Step: 1100, Loss: 0.37716543674468994, Accuracy: 89.72%\n",
      "Epoch: 7, Step: 1150, Loss: 0.520779550075531, Accuracy: 89.68%\n",
      "Epoch: 8, Step: 0, Loss: 0.43569669127464294, Accuracy: 87.15%\n",
      "Epoch: 8, Step: 50, Loss: 0.5665028095245361, Accuracy: 87.74%\n",
      "Epoch: 8, Step: 100, Loss: 0.5594227313995361, Accuracy: 87.95%\n",
      "Epoch: 8, Step: 150, Loss: 0.560095489025116, Accuracy: 88.19%\n",
      "Epoch: 8, Step: 200, Loss: 0.6977443695068359, Accuracy: 88.26%\n",
      "Epoch: 8, Step: 250, Loss: 0.795815110206604, Accuracy: 88.29%\n",
      "Epoch: 8, Step: 300, Loss: 0.545807421207428, Accuracy: 88.4%\n",
      "Epoch: 8, Step: 350, Loss: 0.5567986369132996, Accuracy: 88.45%\n",
      "Epoch: 8, Step: 400, Loss: 0.5000472068786621, Accuracy: 88.42%\n",
      "Epoch: 8, Step: 450, Loss: 0.44449111819267273, Accuracy: 88.45%\n",
      "Epoch: 8, Step: 500, Loss: 0.452149361371994, Accuracy: 88.46%\n",
      "Epoch: 8, Step: 550, Loss: 0.4571000933647156, Accuracy: 88.51%\n",
      "Epoch: 8, Step: 600, Loss: 0.4973334074020386, Accuracy: 88.54%\n",
      "Epoch: 8, Step: 650, Loss: 0.4758448004722595, Accuracy: 88.58%\n",
      "Epoch: 8, Step: 700, Loss: 0.5129988789558411, Accuracy: 88.68%\n",
      "Epoch: 8, Step: 750, Loss: 0.4538382291793823, Accuracy: 88.59%\n",
      "Epoch: 8, Step: 800, Loss: 0.33290085196495056, Accuracy: 88.71%\n",
      "Epoch: 8, Step: 850, Loss: 0.4389592111110687, Accuracy: 88.66%\n",
      "Epoch: 8, Step: 900, Loss: 0.4119832515716553, Accuracy: 88.73%\n",
      "Epoch: 8, Step: 950, Loss: 0.5019590854644775, Accuracy: 88.72%\n",
      "Epoch: 8, Step: 1000, Loss: 0.33054545521736145, Accuracy: 88.68%\n",
      "Epoch: 8, Step: 1050, Loss: 0.39955469965934753, Accuracy: 88.72%\n",
      "Epoch: 8, Step: 1100, Loss: 0.5780852437019348, Accuracy: 88.92%\n",
      "Epoch: 8, Step: 1150, Loss: 0.4911113679409027, Accuracy: 88.88%\n",
      "Epoch: 9, Step: 0, Loss: 0.6495161652565002, Accuracy: 84.58%\n",
      "Epoch: 9, Step: 50, Loss: 0.7328416705131531, Accuracy: 85.32%\n",
      "Epoch: 9, Step: 100, Loss: 0.660767674446106, Accuracy: 85.8%\n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10               \n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001             \n",
    "TSNE = False\n",
    "\n",
    "#load MNIST dataset\n",
    "train_loader, test_loader = load_mnist(BATCH_SIZE)\n",
    "print(len(train_loader.dataset))\n",
    "print(len(test_loader.dataset))\n",
    "\n",
    "# create model instance\n",
    "hebbnet = HebbNet([784,2000],lr=LR,require_hebb=True,activation=True,update_rule='gupta',p=60)\n",
    "fcn = FCN([2000,10])\n",
    "\n",
    "semihebbnet = SemiHebbNet(hebbnet, fcn)\n",
    "\n",
    "# optimizer and loss function\n",
    "optimizer = torch.optim.Adam(semihebbnet.parameters(), lr=LR)  \n",
    "loss_func = nn.CrossEntropyLoss()                  \n",
    "\n",
    "# train networks\n",
    "train_semihebb(model=semihebbnet, train_loader=train_loader, test_loader=test_loader, optimizer=optimizer, loss_func=loss_func, epochs=EPOCH, tsne_enabled=TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "test_accuracy(model=semihebbnet, dataset='mnist', flatten_input=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinningup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
